package com.harshwarghade.project.service;

import com.harshwarghade.project.dto.BankTxn;
import com.harshwarghade.project.dto.PageResponse;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.core.ParameterizedTypeReference;
import org.springframework.http.HttpMethod;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;
import org.springframework.web.reactive.function.client.WebClient;
import org.springframework.http.ResponseEntity;

import java.util.concurrent.*;
import java.util.concurrent.atomic.AtomicLong;

@Service
@RequiredArgsConstructor
@Slf4j
public class BankMigrationService {

    private final RestTemplate restTemplate;
    private final JdbcTemplate jdbcTemplate;
    private final WebClient webClient;

    private static final String BANK_API_URL = "http://localhost:8081/api/bank/transactions?page=%d&size=%d";

    // ðŸ”¥ Optimized for local machine + large dataset
    private static final int PAGE_SIZE = 10000; // reduces API calls drastically
    private static final int BATCH_SIZE = 5000; // optimal JDBC batch for MySQL
    private static final int THREAD_COUNT = 8; // safe default for local CPU , next 8 threads

    // Restart-safe (skips duplicates due to UNIQUE source_txn_id)
    private static final String INSERT_SQL = "INSERT IGNORE INTO transactions_copy " +
            "(amount, timestamp, type, account_id,account_number, source_txn_id) " +
            "VALUES (?, ?, ?, ?, ?, ?)";

    public void migrateAllTransactions() throws InterruptedException {

        long startTime = System.currentTimeMillis();
        AtomicLong totalMigrated = new AtomicLong(0);

        log.info("ðŸš€ Starting MULTI-THREADED Bank Migration...");
        log.info("Page Size: {} | Batch Size: {} | Threads: {}",
                PAGE_SIZE, BATCH_SIZE, THREAD_COUNT);

        // Step 1: Fetch first page to get totalPages
        PageResponse<BankTxn> firstPage = fetchPage(0);

        if (firstPage == null || firstPage.getContent() == null) {
            log.error("Failed to fetch first page from Bank API. Aborting.");
            return;
        }

        int totalPages = firstPage.getTotalPages();
        log.info("Total Pages to Process: {}", totalPages);

        // Step 2: Create thread pool
        ExecutorService executor = Executors.newFixedThreadPool(THREAD_COUNT);

        // Step 3: Submit all page tasks (parallel execution)
        for (int page = 0; page < totalPages; page++) {
            final int currentPage = page;

            executor.submit(() -> {
                try {
                    processPage(currentPage, totalMigrated);
                } catch (Exception e) {
                    log.error("Error processing page {}", currentPage, e);
                }
            });
        }

        // Step 4: Shutdown and wait for completion
        executor.shutdown();
        boolean finished = executor.awaitTermination(12, TimeUnit.HOURS);

        long totalTimeSec = (System.currentTimeMillis() - startTime) / 1000;

        if (finished) {
            log.info("ðŸŽ‰ MIGRATION COMPLETED SUCCESSFULLY!");
            log.info("Total Records Migrated: {}", totalMigrated.get());
            log.info("Total Time Taken: {} seconds (~{} minutes)",
                    totalTimeSec, totalTimeSec / 60);
        } else {
            log.error("Migration did not finish within expected time!");
        }
    }

    // private void processPage(int page, AtomicLong totalMigrated) {

    // long pageStart = System.currentTimeMillis();

    // PageResponse<BankTxn> pageData = fetchPage(page);

    // if (pageData == null || pageData.getContent() == null ||
    // pageData.getContent().isEmpty()) {
    // log.warn("Page {} returned empty data.", page);
    // return;
    // }

    // var transactions = pageData.getContent();

    // // ðŸ”¥ Ultra-fast JDBC batch insert (no Hibernate overhead)
    // jdbcTemplate.batchUpdate(
    // INSERT_SQL,
    // transactions,
    // BATCH_SIZE,
    // (ps, txn) -> {
    // ps.setDouble(1, txn.getAmount());
    // ps.setObject(2, txn.getTimestamp());
    // ps.setString(3, txn.getType());
    // ps.setLong(4, txn.getAccountId());
    // ps.setLong(5, txn.getId()); // source_txn_id for dedup safety
    // }
    // );

    // long migrated = totalMigrated.addAndGet(transactions.size());
    // long pageTimeSec = (System.currentTimeMillis() - pageStart) / 1000;

    // // Reduce logging overhead (log every 10 pages)
    // if (page % 10 == 0) {
    // log.info("Page {} done | Records: {} | Page Time: {} sec | Total Migrated:
    // {}",
    // page, transactions.size(), pageTimeSec, migrated);
    // }
    // }

    private void processPage(int page, AtomicLong totalMigrated) {

        long pageStart = System.currentTimeMillis();

        PageResponse<BankTxn> pageData = fetchPage(page);

        if (pageData == null || pageData.getContent() == null || pageData.getContent().isEmpty()) {
            log.warn("Page {} returned empty data.", page);
            return;
        }

        var transactions = pageData.getContent();

        jdbcTemplate.batchUpdate(
                INSERT_SQL,
                transactions,
                BATCH_SIZE,
                (ps, txn) -> {
                    ps.setDouble(1, txn.getAmount());
                    ps.setObject(2, txn.getTimestamp());
                    ps.setString(3, txn.getType());
                    // ps.setLong(4, txn.getAccountId()); // existing FK
                    if (txn.getAccountId() != null) {
                        ps.setLong(4, txn.getAccountId());
                    } else {
                        ps.setNull(4, java.sql.Types.BIGINT);
                        log.warn("Skipping txn {} due to NULL accountId", txn.getId());
                    }
                    ps.setString(5, txn.getAccountNumber()); // ðŸ”¥ NEW FIELD
                    ps.setLong(6, txn.getId()); // source_txn_id (dedup)
                });

        long migrated = totalMigrated.addAndGet(transactions.size());
        long pageTimeSec = (System.currentTimeMillis() - pageStart) / 1000;

        if (page % 10 == 0) {
            log.info("Page {} done | Records: {} | Page Time: {} sec | Total Migrated: {}",
                    page, transactions.size(), pageTimeSec, migrated);
        }
    }

    private PageResponse<BankTxn> fetchPage(int page) {
        try {
            return webClient.get()
                    .uri(uriBuilder -> uriBuilder
                            .path("/api/bank/transactions")
                            .queryParam("page", page)
                            .queryParam("size", PAGE_SIZE)
                            .build())
                    .retrieve()
                    .bodyToMono(new ParameterizedTypeReference<PageResponse<BankTxn>>() {
                    })
                    .block();
        } catch (Exception e) {
            log.error("Failed to fetch page {}", page, e);
            return null;
        }
    }

}
